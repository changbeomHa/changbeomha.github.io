---
title : 캡스톤 디자인 개발 일지- 논문 세미나
date : 2022-09-13 22:30:51 +09:00
comments: true
categories : [캡스톤 디자인]
tags : [deep learning]
---

개발에 앞서, 타겟 논문 Motion Puzzle: Arbitrary Motion Style Transfer by Body Part에 대한 세미나를 진행하였다. 이번 포스트에는 논문에 대한 간략한 설명을 포스팅할 것이다.  
딥러닝에 대한 기본 이해가 필요하다. 네트워크 동작 방식 및 그래프 구조, 가중치 등 기본 개념을 알고 있으면 논문을 읽는데 많은 도움이 된다.    
같은 팀원 중 한 분이 제작한 세미나 자료를 기반으로 포스트를 한다.  
<br/>

### 논문 Contribution
• 개별 신체 부위의 모션 스타일을 제어할 수 있는 최초의 모션 스타일 전송 방법이다.  
• 새로운 2단계 스타일 적응 네트워크인 BP StyleNet 및 BP ATN은 모션 스타일의 global 및 local 기능을 spatially하게, 그리고 temporally하게 transfer한다.  
• style labeling이나 training data의 모션 pairing 없이 Arbitrary(zero-shot) style transfer 가능하다.  
<br/>

### Architecture
<center><img src="/assets/img/posts/capstone design/그림2.png" width="1000"/></center>

### Motion
위 사진에 대한 보충 설명이다.  
<center><img src="/assets/img/posts/capstone design/그림3.png" width="500"/></center>
타겟 모션은 스타일 추출을 위한 모션이며, 이는 신체 또는 신체 부위가 그 대상이 될 수 있다.  
<br/>
<center><img src="/assets/img/posts/capstone design/그림4.png" width="150"/></center>
소스 모션은 content를 위한 모션이며, 출력 동작을 위한 모션으로 설명된다.  
<br/>

### Spatial-temporal graph
<center><img src="/assets/img/posts/capstone design/그림5.png" width="200"/></center>
위 그림에서 노란 선으로 이어진 부분은 Temporal graph이며, 아는 single vertex들의 consecutive한 상태를 나타낸다.  
또한 위 그림에서 붉은 선으로 이어진 부분이 Spatial graph이며, single frame의 전체 모션을 나타낸다.  
즉 시간적, 공간적인 특성의 그래프라고 이해할 수 있다.  
<br/>

### Skeleton based graph convolutional network
<center><img src="/assets/img/posts/capstone design/그림6.png" width="150"/></center>
사진의 정점 v에 대하여, 컨볼루션 네트워크의 수식은 아래와 같다.  
<center><img src="/assets/img/posts/capstone design/그림7.png" width="450"/></center>
<center><img src="/assets/img/posts/capstone design/그림8.png" width="300"/></center>
<center><img src="/assets/img/posts/capstone design/그림9.png" width="600"/></center>
<br/>

### Graph pooling and unpooling
<center><img src="/assets/img/posts/capstone design/그림10.png" width="700"/></center>
위 사진은 그래프 폴링에 대한 것이다.  
여러 해상도의 경우를 위해 temporal dimension에 대한 표준 평균 풀링, spaatial dimensioni에 대한 특정 평균 풀링을 고려한다.  
<br/>

### Style Encoder
<center><img src="/assets/img/posts/capstone design/그림11.png" width="800"/></center>
위 그림은 multi level encoding block 연결과정으로써, 중간 스타일 특징을 점진적으로 추출한다.
<br/>

### Content encodeer
<center><img src="/assets/img/posts/capstone design/그림12.png" width="600"/></center>
Content encoder를 보면, Style encoder와 유사함을 알 수 있다.  
하지만 style normalization에는 IN을 사용하며, Content encoder는 최종 output에만 사용된다.  
<br/>

### Decoder
<center><img src="/assets/img/posts/capstone design/그림13.png" width="500"/></center>
Decoder는 content feature을 output motion으로 변환한다.  
• style feature의 global 및 local characteristics를 transfer한다.  
fs^Gi에서 fd^Gi로 거치는 과정을 2단계 transfer 모듈을 통해 가는데, 이 모듈에서 각각 BP-AdaIN, BP-ATN이 사용된다.  
<br/>

###  BP-AdaIN
논문에서 사용된 BP-AdaIN 공식을 살펴보자.
<center><img src="/assets/img/posts/capstone design/그림14.png" width="800"/></center>
• f hat d ^ Gi를 생성하기 위해 style feature의 global statistics를 transfer한다.  
• fd^Gi를 입력으로 취하고 신체 부위별로 AdaIN을 적용하여 style feature fs^Gi를 inject 한다.  
<br/>

###  BP-ATN
BP-AdaIn에 이어 BP-ATN은 어떻게 적용되었는지 알아보자.  
• locally semantic style feature를 transfer한다.  
• 동일한 신체 부위의 part-feature 간의 대응 관계를 매핑한다.  
<center><img src="/assets/img/posts/capstone design/그림15.png" width="600"/></center>
<br/>
<center><img src="/assets/img/posts/capstone design/그림16.png" width="600"/></center>
• 위에서 수식의 좌변은 style feature의 α번째 vertex과 decoded feature의 β번째 vertex 사이의 similarity를 측정한다.  
• 두 vertex 사이의 similarity가 높을수록 두 vertex 사이의 spatial-temporal 상관관계가 더 커지게 된다.  
<center><img src="/assets/img/posts/capstone design/그림17.png" width="400"/></center>
